# Project Name: PJML_bert_toxicity

## Description:
This project has been constructed for the course `Project Machine Learning` in Winter 2023/2024. We implemented BERT (Bidirectional Encoder Representations from Transformers) from scratch to detect toxic content in text. 
Below we provide an overview over our approach and results. For more details, read the [report 1](Project_Machine_Learning_MS1.pdf), [report 2](Project_Machine_Learning_MS2.pdf), and [report 3](Project_Machine_Learning_MS3.pdf).

### BERT


### Data
We used the data from kaggle

### Hyperparameteroptimization
We perform Hyperparameteroptimization to find an 'optimal' model 

### Explainable AI (XAI) 
We use Integrated Gradients to 

## Installation:
1. Clone the repository: `git clone https://github.com/your-username/PJML_bert_toxicity.git`
2. Navigate to the project directory: `cd PJML_bert_toxicity`
3. Install the required dependencies: `pip install -r requirements.txt`

## Usage:
1. Prepare your dataset by organizing toxic and non-toxic text samples.
2. Preprocess the data by cleaning and tokenizing the text.
3. Train the BERT model using the preprocessed data.
4. Evaluate the model's performance on a validation set.
5. Use the trained model to classify new text inputs for toxicity.
