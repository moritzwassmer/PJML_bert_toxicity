{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install captum --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "from models import *\n",
    "\n",
    "model = Model()\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "# Load the model using CPU_Unpickler\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    model = CPU_Unpickler(file).load()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(*inputs):\n",
    "    out = model(*inputs)[0]\n",
    "    return out.unsqueeze(0)#torch.sigmoid(out)\n",
    "\n",
    "model_input = model.base_model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "lig = LayerIntegratedGradients(model_output, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "import torch\n",
    "\n",
    "def construct_input_and_baseline(text):\n",
    "    max_length = 510\n",
    "    baseline_token_id = TOKENIZER.pad_token_id\n",
    "    sep_token_id = TOKENIZER.sep_token_id\n",
    "    cls_token_id = TOKENIZER.cls_token_id\n",
    "\n",
    "    # Encode text with max_length set to 512\n",
    "    text_ids = TOKENIZER.encode(text, truncation=True, add_special_tokens=False)\n",
    "    #print(text_ids)\n",
    "    token_list_sum = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    token_list_1 = TOKENIZER.convert_ids_to_tokens(token_list_sum)\n",
    "    #print(token_list_1)\n",
    "\n",
    "    # Pad or truncate to exactly 512 tokens\n",
    "    pad_length = max_length - len(text_ids)\n",
    "    if pad_length > 0:\n",
    "        text_ids += [baseline_token_id] * pad_length\n",
    "    else:\n",
    "        text_ids = text_ids[:max_length]\n",
    "\n",
    "    # Construct input_ids and baseline_input_ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
    "    token_list_sum = [cls_token_id] + token_list_1 + [sep_token_id]\n",
    "\n",
    "    # Convert to tensor\n",
    "    input_ids_tensor = torch.tensor([input_ids], device='cpu')\n",
    "    baseline_input_ids_tensor = torch.tensor([baseline_input_ids], device='cpu')\n",
    "\n",
    "    # Convert input_ids to tokens\n",
    "    #print(input_ids)\n",
    "    token_list = TOKENIZER.convert_ids_to_tokens(input_ids)\n",
    "    #print(token_list)\n",
    "\n",
    "    return input_ids_tensor, baseline_input_ids_tensor, token_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Your input text here.'\n",
    "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "\n",
    "print(f'original text: {input_ids}')\n",
    "print(f'baseline text: {baseline_input_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class_index=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                    target=target_class_index,\n",
    "                                    baselines=baseline_input_ids,\n",
    "                                    return_convergence_delta=True,\n",
    "                                    internal_batch_size=1)\n",
    "print(attributions.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "def explain(text, **labels_and_values):\n",
    "\n",
    "    label_to_index_mapping = {'toxic': 0, 'severe_toxic': 1, 'obscene': 2, 'threat': 3, 'insult': 4, 'identity_hate': 5}\n",
    "\n",
    "    visualizations = []\n",
    "\n",
    "    for label, value in labels_and_values.items():\n",
    "        print(label)\n",
    "        print(value)\n",
    "        target_class_index = label_to_index_mapping[label]\n",
    "        print(target_class_index)  # Using the mapping to get the index\n",
    "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "        attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                            target= target_class_index, #target_class_index,\n",
    "                                            baselines=baseline_input_ids,\n",
    "                                            return_convergence_delta=True,\n",
    "                                            internal_batch_size=1)\n",
    "        attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "        score_vis = viz.VisualizationDataRecord(\n",
    "            word_attributions=attributions_sum,\n",
    "            pred_prob=torch.sigmoid(model(input_ids)[0][target_class_index]),\n",
    "            pred_class=torch.sigmoid(model(input_ids)[0][target_class_index]).round(),\n",
    "            true_class=value,\n",
    "            attr_class=text,\n",
    "            attr_score=attributions_sum.sum(),\n",
    "            raw_input_ids=all_tokens,\n",
    "            convergence_score=delta\n",
    "        )\n",
    "\n",
    "        visualizations.append(score_vis)\n",
    "\n",
    "    viz.visualize_text(visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"try it here\", toxic=1, severe_toxic=2, obscene=3, threat=4, insult=5, identity_hate=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
