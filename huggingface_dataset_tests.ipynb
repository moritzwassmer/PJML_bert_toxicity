{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802591b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install datasets\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ce3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464fe5e",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc737c1",
   "metadata": {},
   "source": [
    "### bookcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b594b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 74004228\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Download + load data from cache or online AUTOMATICALLY\n",
    "# https://huggingface.co/docs/datasets/loading#slice-splits\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bookcorpus\") # alternative, less size datasets.load_dataset(\"bookcorpus\", split=\"train[:10%]\")\n",
    "# saved here on windows C:\\Users\\morit\\.cache\\huggingface\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f56493",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a6ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual save to disk\n",
    "\n",
    "#folder_path = r\"C:\\Users\\morit\\OneDrive\\UNI\\Master\\WS23\\PML\\repo\\bert_from_scratch.toxic_comment\\datasets\\pretraining\"\n",
    "#full_path = folder_path+r\"\\bookcorpus\"\n",
    "\n",
    "#dataset.save_to_disk(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800cfd29",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77b037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# manual load from disk\n",
    "\n",
    "#dataset = datasets.load_dataset(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c35a8",
   "metadata": {},
   "source": [
    "#### Tests with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ad4c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 74004228\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4604f83",
   "metadata": {},
   "source": [
    "#### slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14821a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][4][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c4a55",
   "metadata": {},
   "source": [
    "#### Standard dataloader - not working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cb2c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['usually , he would be tearing around the living room , playing with his toys .',\n",
       "  'but just one look at a minion sent him practically catatonic .']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset[\"train\"], batch_size=2)\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebacda",
   "metadata": {},
   "source": [
    "#### Tokenizer - use pretrained, at least for prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012af1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/preprocessing\n",
    "# https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")  # Choose an appropriate tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ead925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.model_max_length = SEQ_LEN # might not be correct in case of pretraining where we add CLS at the end, check that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40987021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.truncation_side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30986546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length # we might need to fixate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afd8af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7632, 1045, 2572, 28461, 1010, 2040, 2024, 2017, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hi i am moritz, who are you ?\"#[\"hi i am moritz\", \"no you are not moritz, you are kevin\"]\n",
    "encoded_input = tokenizer(text)#,padding=True, truncation=True)\n",
    "# , return_tensors='pt') use this for pt tensors\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "432fff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7632, 1045, 2572, 28461, 1010, 2040, 2024, 2017, 1029, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f874a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hi i am moritz, who are you? [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d582933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd670441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[MASK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b4d7e",
   "metadata": {},
   "source": [
    "#### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8564c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "class Bookcorpus(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, seq_len=SEQ_LEN):\n",
    "        self.dataset = load_dataset(\"bookcorpus\")[\"train\"]\n",
    "        self.nrows = len(self.dataset) \n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nrows\n",
    "\n",
    "    def __getitem__(self, item): # TODO Where is truncation if sequence is to long? How is ensured that both sentences fit into the sequence?\n",
    "        \n",
    "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
    "        s1, s2, is_next_label = self.get_sent(item)\n",
    "        \n",
    "        # Step 2: replace random words in EACH sentence with mask / random words # copied \n",
    "        t1_random, t1_label = self.random_word(s1)\n",
    "        t2_random, t2_label = self.random_word(s2)\n",
    "        \n",
    "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences # copied \n",
    "         # Adding PAD token for labels\n",
    "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
    "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
    "\n",
    "        # Step 4: combine sentence 1 and 2 as one input # copied \n",
    "        # adding PAD tokens to make the sentence same length as seq_len\n",
    "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
    "        bert_input = (t1 + t2)[:self.seq_len]\n",
    "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
    "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
    "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
    "\n",
    "        output = {\"bert_input\": bert_input,\n",
    "                  \"bert_label\": bert_label,\n",
    "                  \"segment_label\": segment_label,\n",
    "                  \"is_next\": is_next_label}\n",
    "\n",
    "        return {key: torch.tensor(value) for key, value in output.items()}\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return  {\"s1\":s1, \"s2\":s2, \"is_next_label\":is_next_label}\n",
    "        #return {\"t1_random\":t1_random, \"t1_label\":t1_label, \"t2_random\":t2_random, \"t2_label\":t2_label}\n",
    "    \n",
    "    def get_sent(self, index): #selfmade\n",
    "        '''gets sentence pair as dicitinary s1, s2, isNext'''\n",
    "        isNext = random.random() > 0.5\n",
    "        \n",
    "        t1 = self.dataset[index][\"text\"]\n",
    "        if isNext:\n",
    "            t2 = self.dataset[index+1][\"text\"]\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            t2 = self.get_random_line(index+1)[\"text\"]\n",
    "            return t1, t2, 0\n",
    "        \n",
    "    def get_random_line(self, excludedIndex): #selfmade\n",
    "        '''return random single sentence excluding'''\n",
    "        randIndex = random.randint(1, self.__len__())\n",
    "            \n",
    "        # ensure that randIndex is not next sentence\n",
    "        while randIndex == excludedIndex:\n",
    "            randIndex = random.randint(1, self.__len__())\n",
    "        \n",
    "        return self.dataset[randIndex]\n",
    "\n",
    "    def random_word(self, sentence): #copied\n",
    "        tokens = sentence.split()\n",
    "        output_label = []\n",
    "        output = []\n",
    "\n",
    "        # 15% of the tokens would be replaced\n",
    "        for i, token in enumerate(tokens):\n",
    "            prob = random.random()\n",
    "\n",
    "            # remove cls and sep token\n",
    "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
    "\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                # 80% chance change token to mask token\n",
    "                if prob < 0.8:\n",
    "                    for i in range(len(token_id)):\n",
    "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
    "\n",
    "                # 10% chance change token to random token\n",
    "                elif prob < 0.9:\n",
    "                    for i in range(len(token_id)):\n",
    "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "\n",
    "                # 10% chance change token to current token\n",
    "                else:\n",
    "                    output.append(token_id)\n",
    "\n",
    "                output_label.append(token_id)\n",
    "\n",
    "            else:\n",
    "                output.append(token_id)\n",
    "                for i in range(len(token_id)):\n",
    "                    output_label.append(0)\n",
    "\n",
    "        # flattening\n",
    "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
    "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
    "        assert len(output) == len(output_label)\n",
    "        #assert len(output) == self.seq_len, \"sequence length not fixed! \"+str(len(output)) # from moritz\n",
    "        return output, output_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e21d7",
   "metadata": {},
   "source": [
    "#### Testing the Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40334c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "test = Bookcorpus(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b123188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(test,batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c86a3b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input': tensor([[ 101, 2788, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 2021, 2074,  ...,    0,    0,    0]]),\n",
       " 'bert_label': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'segment_label': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'is_next': tensor([1, 1])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed0ac1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#is sewuence length fixed?\n",
    "for i in range(1,1000):\n",
    "    batch = next(iter(dl))\n",
    "    for j in range(1,2): # batchsize\n",
    "        length_ = len(batch[\"bert_input\"][j])\n",
    "        #print(length_)\n",
    "        assert length_==SEQ_LEN, \"sequence size is not \"+str(SEQ_LEN)+\": \"+ str(length_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226e006",
   "metadata": {},
   "source": [
    "## Finetuning - download from kaggle and extract in finetuning folder. Delete the zips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2f30c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
       "        num_rows: 159571\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
       "        num_rows: 63978\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_path = r\"C:\\Users\\morit\\OneDrive\\UNI\\Master\\WS23\\PML\\repo\\bert_from_scratch.toxic_comment\\datasets\\finetuning\\kaggle-toxic_comment\"\n",
    "toxic_dataset = load_dataset(\"jigsaw_toxicity_pred\", data_dir=toxic_path)\n",
    "toxic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd0356",
   "metadata": {},
   "source": [
    "#### Test with standard dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f394a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_text': [\"Right Sector \\n\\nRight Sector is involved in the current conflict occurring in the Donbass region. I am now aware you have a biasness for your lack of justification in removing material which is well known. Because you seem to think it's fine to remove the Right Sector from the info-box, I will remove the RNU , as I can see no fairer way then to remove a Russian-centric group while you unjustifiably removed a Ukrainian-centric group, and labeled the addition of them as not 'constructive'. There is a better case to be made for Right Sector involvement in the conflict rather than RNU involvement.\"],\n",
       " 'toxic': tensor([0]),\n",
       " 'severe_toxic': tensor([0]),\n",
       " 'obscene': tensor([0]),\n",
       " 'threat': tensor([0]),\n",
       " 'insult': tensor([0]),\n",
       " 'identity_hate': tensor([0])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(toxic_dataset[\"train\"], batch_size=1, shuffle = True)\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a7997a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2157, 4753, 2157, 4753, 2003, 2920, 1999, 1996, 2783, 4736, 10066, 1999, 1996, 2123, 22083, 2015, 2555, 1012, 1045, 2572, 2085, 5204, 2017, 2031, 1037, 13827, 2791, 2005, 2115, 3768, 1997, 19777, 1999, 9268, 3430, 2029, 2003, 2092, 2124, 1012, 2138, 2017, 4025, 2000, 2228, 2009, 1005, 1055, 2986, 2000, 6366, 1996, 2157, 4753, 2013, 1996, 18558, 1011, 3482, 1010, 1045, 2097, 6366, 1996, 29300, 2226, 1010, 2004, 1045, 2064, 2156, 2053, 4189, 2121, 2126, 2059, 2000, 6366, 1037, 2845, 1011, 9358, 7277, 2177, 2096, 2017, 4895, 29427, 10128, 2401, 6321, 3718, 1037, 5969, 1011, 9358, 7277, 2177, 1010, 1998, 12599, 1996, 2804, 1997, 2068, 2004, 2025, 1005, 26157, 1005, 1012, 2045, 2003, 1037, 2488, 2553, 2000, 2022, 2081, 2005, 2157, 4753, 6624, 1999, 1996, 4736, 2738, 2084, 29300, 2226, 6624, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(batch[\"comment_text\"])\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc5db146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "flattened = list(chain(*(encoded_input[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f36a258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] right sector right sector is involved in the current conflict occurring in the donbass region. i am now aware you have a biasness for your lack of justification in removing material which is well known. because you seem to think it's fine to remove the right sector from the info - box, i will remove the rnu, as i can see no fairer way then to remove a russian - centric group while you unjustifiably removed a ukrainian - centric group, and labeled the addition of them as not'constructive '. there is a better case to be made for right sector involvement in the conflict rather than rnu involvement. [SEP]\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411158c",
   "metadata": {},
   "source": [
    "#### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65f9e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicComment(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, seq_len=SEQ_LEN, split=\"train\",):\n",
    "        \n",
    "        if not split in [\"train\",\"test\"]:\n",
    "            raise ValueError(\"Parameter has to be 'train' or 'test'\")\n",
    "        \n",
    "        self.dataset = load_dataset(\"jigsaw_toxicity_pred\", data_dir=toxic_path)[split]\n",
    "        self.nrows = len(self.dataset) \n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nrows\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        # Step 1: get row\n",
    "        row = self.dataset[item]\n",
    "        #print(row)\n",
    "        \n",
    "        # Step 2: encode comment\n",
    "        row[\"bert_input\"] = tokenizer(row[\"comment_text\"],padding=True, truncation=True, return_tensors='pt')[\"input_ids\"]\n",
    "        \n",
    "        # TODO\n",
    "        #print(row[\"bert_input\"])\n",
    "        \n",
    "        return row[\"bert_input\"]\n",
    "\n",
    "    \n",
    "    def get_sent(self, index): #selfmade\n",
    "        '''gets sentence pair as dicitinary s1, s2, isNext'''\n",
    "        isNext = random.random() > 0.5\n",
    "        \n",
    "        t1 = self.dataset[index][\"text\"]\n",
    "        if isNext:\n",
    "            t2 = self.dataset[index+1][\"text\"]\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            t2 = self.get_random_line(index+1)[\"text\"]\n",
    "            return t1, t2, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3c0766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  101,  7526,  2339,  1996, 10086,  2015,  2081,  2104,  2026,  5310,\n",
       "          18442, 13076, 12392,  2050,  5470,  2020, 16407,  1029,  2027,  4694,\n",
       "           1005,  1056,  3158,  9305, 22556,  1010,  2074,  8503,  2006,  2070,\n",
       "           3806,  2044,  1045,  5444,  2012,  2047,  2259, 14421,  6904,  2278,\n",
       "           1012,  1998,  3531,  2123,  1005,  1056,  6366,  1996, 23561,  2013,\n",
       "           1996,  2831,  3931,  2144,  1045,  1005,  1049,  3394,  2085,  1012,\n",
       "           6486,  1012, 16327,  1012,  4229,  1012,  2676,   102]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = ToxicComment(tokenizer)\n",
    "dl2 = DataLoader(test2,batch_size=1,shuffle=False)\n",
    "next(iter(dl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a974b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(dl2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(dl))[\"bert_input\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d051a75",
   "metadata": {},
   "source": [
    "* Ensure that during pre training, both sentences fit into the model at the same time -> seq_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
